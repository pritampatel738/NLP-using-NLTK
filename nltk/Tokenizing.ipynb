{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenizers =word tokenizers ........sentence tokenizers.... breaking a text in sentences and words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#corpora...body of text ...eg..medical journal...presidential speeches...english language..\n",
    "#lexicon....words and their  meanings...eg.investor-speak...regular speak...\n",
    "# investor  speak 'bull' = someone who is positive about the market..\n",
    "# english speak 'bull' = scary animal you don't want to run @ you..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_text=\"Hello there,how are you doing today? The weather is awesome today and Python is awesome. The sky is pinkish-blue. You should not eat cardboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sent_tokenize(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(word_tokenize(example_text)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "li=[]\n",
    "s='a'\n",
    "while(s<)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_tokenize(l):\n",
    "    toked=[]\n",
    "    for i in []\n",
    "    #for i in l:\n",
    "        #print(\"a\")\n",
    "        #if i<\n",
    "    \n",
    "word_tokenize(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is iit ism dhanbad', 'Is this place nice', ' Hey Mr', ' Pritam Patel ']\n",
      "['this', 'is', 'iit', 'ism', 'dhanbad', 'Is', 'this', 'place', 'nice', ' Hey', 'Mr', ' Pritam', 'Patel']\n",
      "\n",
      "\n",
      "\n",
      "A complete sentence has at least a subject\n",
      " and a main verb to state (declare) a complete thought. Short example: Walker walks. A subject is the noun that is doing the main verb. The main verb is the verb that the subject is doing. In English and many other languages, the first word of a written sentence has a capital letter. At the end of the sentence there is a full stop or full point (American: 'period').\n",
      "\n",
      "\n",
      "\n",
      "A complete sentence has at least a subject\n",
      "\n",
      " and a main verb to state (declare) a complete thought\n",
      "\n",
      " Short example: Walker walks\n",
      "\n",
      " A subject is the noun that is doing the main verb\n",
      "\n",
      " The main verb is the verb that the subject is doing\n",
      "\n",
      " In English and many other languages, the first word of a written sentence has a capital letter\n",
      "\n",
      " At the end of the sentence there is a full stop or full point (American: 'period')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" this is the tokenization of any paragraph in\n",
    "        word and sentence manner...\n",
    "        (.) ,(!),(?) has been used for sentence tokenization and\n",
    "        only \"space\" has been used for word tokenization\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "l=\"this is iit ism dhanbad.Is this place nice? Hey Mr. Pritam Patel .\"\n",
    "alphabet_capital=['A','B','C','D','E','F','G','H',\n",
    "\t\t\t\t'I','J','K','L','M','N','O','P','Q','R','S','T',\n",
    "\t\t\t\t'U','V','W','X','Y','Z']\n",
    "alphabet_small=['a','b','c','d','e','f','g','h','i','j','k','l','m','n',\n",
    "                    'o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "def large(s):\n",
    "    for i in alphabet_capital:\n",
    "        if s==i:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def small(s):\n",
    "    for i in alphabet_small:\n",
    "        if i==s:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def word_tokenize(l):\n",
    "    s=\"\"\n",
    "    final=[] ## the list that is to be returned..or this is the tokenized list\n",
    "    flag=False\n",
    "    for i in range(len(l)):\n",
    "        \n",
    "        if not(large(l[i]) or small(l[i])) and  flag:\n",
    "            final.append(s) ## appending the value to the final tokenized array ....\n",
    "            flag=False \n",
    "            s=\"\"  ## setting the value of s to be null string so that it can store the next value of the string before .\n",
    "        else:\n",
    "            flag=True\n",
    "            s+=l[i] ## concatenating all the values before any . is observed...\n",
    "    final1=[]\n",
    "    t=\"\"\n",
    "    #for i in range(len(final)):\n",
    "        #for j in range(len(final[i])):\n",
    "            #if final[i][j]==' ':\n",
    "                #continue\n",
    "            #else:\n",
    "                #t+=final[i][j]\n",
    "        #final1.append(t)\n",
    "        \n",
    "    #return final1\n",
    "    return final\n",
    "\n",
    "\n",
    "def sentence_tokenizer(l):\n",
    "    s=\"\"\n",
    "    final=[]\n",
    "    for i in l:\n",
    "        if i=='.' or i=='?' or i=='!' or i=='\\n':\n",
    "            final.append(s)\n",
    "            s=\"\"\n",
    "        else:\n",
    "            s+=i\n",
    "    return final\n",
    "\n",
    "        \n",
    "\n",
    "para=\"A complete sentence has at least a subject\\n and a main verb to state (declare) a complete thought. Short example: Walker walks. A subject is the noun that is doing the main verb. The main verb is the verb that the subject is doing. In English and many other languages, the first word of a written sentence has a capital letter. At the end of the sentence there is a full stop or full point (American: 'period').\"\n",
    "print(sentence_tokenizer(l))\n",
    "print(word_tokenize(l))\n",
    "for i in range(3):\n",
    "    print(\"\")\n",
    "x=[]\n",
    "x=sentence_tokenizer(para)\n",
    "\n",
    "#print(word_tokenize(para))\n",
    "print(para)\n",
    "print(\"\\n\\n\")\n",
    "for i in x:\n",
    "    print(i,end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
